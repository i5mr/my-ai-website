import streamlit as st
import google.generativeai as genai

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª (Ø«Ø¨Ø§Øª ÙƒØ§Ù…Ù„ Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø±ÙŠØ§Ù† Ø§Ù„Ù…Ø·ÙˆØ±", page_icon="ğŸ¤–", layout="centered")

st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo&display=swap');
    html, body, [class*="css"] { 
        font-family: 'Cairo', sans-serif; 
        direction: rtl; 
        text-align: right; 
    }
    .stChatMessage { text-align: right; direction: rtl; border-radius: 15px; }
    /* Ø¥ØµÙ„Ø§Ø­ Ù…ÙƒØ§Ù† Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª Ø§Ù„Ø¨ÙˆØª ÙˆØ§Ù„Ù…Ø³ØªØ®Ø¯Ù… */
    .stChatMessage [data-testid="stChatMessageAvatarUser"] { order: 1; }
    .stChatMessage [data-testid="stChatMessageAvatarAssistant"] { order: 1; }
    </style>
    """, unsafe_allow_html=True)

# 2. Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ (Secrets)
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception:
    st.error("âš ï¸ Ø®Ø·Ø£: Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ GOOGLE_API_KEY ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Secrets.")
    st.stop()

# 3. Ø¯Ø§Ù„Ø© Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­ (Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© 404 ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©)
@st.cache_resource
def load_model():
    # Ù†Ø­Ø§ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø±Ø©
    try:
        return genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            system_instruction="Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø¬Ø¯Ø§Ù‹ Ø§Ø³Ù…Ùƒ 'Ù…Ø³Ø§Ø¹Ø¯ Ø±ÙŠØ§Ù†'ØŒ Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© ÙˆØªØªØ­Ø¯Ø« Ø¨Ø£Ø³Ù„ÙˆØ¨ ÙˆØ¯ÙŠ."
        )
    except:
        # Ø¥Ø°Ø§ ÙØ´Ù„ØªØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ©
        return genai.GenerativeModel(model_name="gemini-pro")

model = load_model()

# 4. Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])

st.title("ğŸ¤– Ù…Ø³Ø§Ø¹Ø¯ Ø±ÙŠØ§Ù† Ø§Ù„Ù…Ø·ÙˆØ±")
st.write("Ù†Ø³Ø®Ø© Ù…Ø¯Ù…Ø¬Ø© ÙˆØ®Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨Ø¥Ø°Ù† Ø§Ù„Ù„Ù‡.")

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
for message in st.session_state.chat.history:
    role = "user" if message.role == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

# 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙˆØ§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if prompt := st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        try:
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø¹ ØªÙØ¹ÙŠÙ„ Ø®Ø§ØµÙŠØ© Ø§Ù„Ù€ Streaming
            response = st.session_state.chat.send_message(prompt, stream=True)
            for chunk in response:
                full_response += chunk.text
                response_placeholder.markdown(full_response + "â–Œ")
            response_placeholder.markdown(full_response)
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)}")
            st.info("Ù†ØµÙŠØ­Ø©: ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API ØµØ­ÙŠØ­ ÙˆÙ„Ù‡ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Gemini.")
